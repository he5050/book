# è¯­éŸ³åŠŸèƒ½ä½¿ç”¨æŒ‡å—

AudioProcessor ç°åœ¨é›†æˆäº†å®Œæ•´çš„è¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆæˆåŠŸèƒ½ï¼ŒåŸºäºæµè§ˆå™¨åŸç”Ÿçš„ Web Speech APIã€‚

## åŠŸèƒ½ç‰¹æ€§

### ğŸ¤ è¯­éŸ³è¯†åˆ« (Speech Recognition)
- å®æ—¶è¯­éŸ³è½¬æ–‡å­—
- æ”¯æŒè¿ç»­è¯†åˆ«å’Œä¸€æ¬¡æ€§è¯†åˆ«
- æ”¯æŒå¤šç§è¯­è¨€ï¼ˆä¸­æ–‡ã€è‹±æ–‡ç­‰ï¼‰
- è¿”å›ç½®ä¿¡åº¦å’Œä¸­é—´ç»“æœ

### ğŸ”Š è¯­éŸ³åˆæˆ (Text-to-Speech)
- æ–‡å­—è½¬è¯­éŸ³æ’­æ”¾
- æ”¯æŒå¤šç§è¯­éŸ³å’Œè¯­è¨€
- å¯è°ƒèŠ‚è¯­é€Ÿã€éŸ³è°ƒã€éŸ³é‡
- æ”¯æŒæ’­æ”¾æ§åˆ¶ï¼ˆæš‚åœã€æ¢å¤ã€åœæ­¢ï¼‰

## åŸºæœ¬ä½¿ç”¨

### 1. æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ

```javascript
const support = AudioProcessor.getSpeechSupport();
console.log('è¯­éŸ³è¯†åˆ«æ”¯æŒ:', support.recognition);
console.log('è¯­éŸ³åˆæˆæ”¯æŒ:', support.synthesis);
```

### 2. è¯­éŸ³è¯†åˆ«

```javascript
const audioProcessor = new AudioProcessor();

// æ–¹æ³•ä¸€ï¼šä¸€æ¬¡æ€§è¯†åˆ«
try {
    const text = await audioProcessor.recognizeOnce('zh-CN');
    console.log('è¯†åˆ«ç»“æœ:', text);
} catch (error) {
    console.error('è¯†åˆ«å¤±è´¥:', error);
}

// æ–¹æ³•äºŒï¼šè¿ç»­è¯†åˆ«
const recognizer = audioProcessor.getSpeechRecognizer();
if (recognizer) {
    recognizer.onResult = (result) => {
        console.log('è¯†åˆ«æ–‡æœ¬:', result.transcript);
        console.log('ç½®ä¿¡åº¦:', result.confidence);
        console.log('æ˜¯å¦æœ€ç»ˆç»“æœ:', result.isFinal);
    };
    
    recognizer.onError = (error) => {
        console.error('è¯†åˆ«é”™è¯¯:', error);
    };
    
    recognizer.start(); // å¼€å§‹è¯†åˆ«
    // recognizer.stop(); // åœæ­¢è¯†åˆ«
}
```

### 3. è¯­éŸ³åˆæˆ

```javascript
// æ–¹æ³•ä¸€ï¼šç®€å•åˆæˆ
try {
    await audioProcessor.speakText('ä½ å¥½ï¼Œä¸–ç•Œï¼');
    console.log('è¯­éŸ³æ’­æ”¾å®Œæˆ');
} catch (error) {
    console.error('åˆæˆå¤±è´¥:', error);
}

// æ–¹æ³•äºŒï¼šè‡ªå®šä¹‰å‚æ•°
await audioProcessor.speakText('Hello World', {
    lang: 'en-US',
    rate: 1.2,    // è¯­é€Ÿ
    pitch: 1.1,   // éŸ³è°ƒ
    volume: 0.8   // éŸ³é‡
});

// æ’­æ”¾æ§åˆ¶
audioProcessor.pauseSpeech();  // æš‚åœ
audioProcessor.resumeSpeech(); // æ¢å¤
audioProcessor.stopSpeech();   // åœæ­¢
```

### 4. é«˜çº§åŠŸèƒ½

```javascript
// è·å–å¯ç”¨è¯­éŸ³åˆ—è¡¨
const voices = audioProcessor.getAvailableVoices();
console.log('å¯ç”¨è¯­éŸ³:', voices);

// è·å–ä¸­æ–‡è¯­éŸ³
const chineseVoices = audioProcessor.getVoicesByLanguage('zh');
console.log('ä¸­æ–‡è¯­éŸ³:', chineseVoices);

// ç›´æ¥ä½¿ç”¨è¯­éŸ³åˆæˆå™¨
const synthesizer = audioProcessor.getSpeechSynthesizer();
if (synthesizer) {
    synthesizer.onStart = () => console.log('å¼€å§‹æ’­æ”¾');
    synthesizer.onEnd = () => console.log('æ’­æ”¾ç»“æŸ');
    synthesizer.speak('è‡ªå®šä¹‰è¯­éŸ³åˆæˆ');
}
```

## åœ¨ React ç»„ä»¶ä¸­ä½¿ç”¨

```jsx
import React, { useState, useRef } from 'react';
import AudioProcessor from './lib/Audio';

const SpeechDemo = () => {
    const audioProcessorRef = useRef(new AudioProcessor());
    const [text, setText] = useState('');
    const [isListening, setIsListening] = useState(false);

    const handleRecognition = async () => {
        try {
            setIsListening(true);
            const result = await audioProcessorRef.current.recognizeOnce();
            setText(result);
        } catch (error) {
            alert('è¯†åˆ«å¤±è´¥: ' + error.message);
        } finally {
            setIsListening(false);
        }
    };

    const handleSpeak = async () => {
        if (text.trim()) {
            try {
                await audioProcessorRef.current.speakText(text);
            } catch (error) {
                alert('åˆæˆå¤±è´¥: ' + error.message);
            }
        }
    };

    return (
        <div>
            <button onClick={handleRecognition} disabled={isListening}>
                {isListening ? 'æ­£åœ¨è¯†åˆ«...' : 'å¼€å§‹è¯­éŸ³è¯†åˆ«'}
            </button>
            
            <textarea 
                value={text} 
                onChange={(e) => setText(e.target.value)}
                placeholder="è¯†åˆ«ç»“æœæˆ–è¾“å…¥æ–‡æœ¬"
            />
            
            <button onClick={handleSpeak}>
                è¯­éŸ³æ’­æ”¾
            </button>
        </div>
    );
};
```

## æµè§ˆå™¨å…¼å®¹æ€§

| åŠŸèƒ½ | Chrome | Edge | Safari | Firefox |
|------|--------|------|--------|---------|
| è¯­éŸ³è¯†åˆ« | âœ… | âœ… | âœ… | âŒ |
| è¯­éŸ³åˆæˆ | âœ… | âœ… | âœ… | âœ… |

## æ³¨æ„äº‹é¡¹

1. **æƒé™è¦æ±‚**ï¼šè¯­éŸ³è¯†åˆ«éœ€è¦éº¦å…‹é£æƒé™
2. **HTTPS è¦æ±‚**ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒä¸­éœ€è¦ HTTPS
3. **è¯­è¨€æ”¯æŒ**ï¼šä¸åŒæµè§ˆå™¨æ”¯æŒçš„è¯­è¨€å¯èƒ½ä¸åŒ
4. **ç½‘ç»œè¦æ±‚**ï¼šæŸäº›æµè§ˆå™¨çš„è¯­éŸ³è¯†åˆ«éœ€è¦ç½‘ç»œè¿æ¥
5. **ç”¨æˆ·äº¤äº’**ï¼šè¯­éŸ³åˆæˆé€šå¸¸éœ€è¦ç”¨æˆ·äº¤äº’åæ‰èƒ½æ’­æ”¾

## é”™è¯¯å¤„ç†

```javascript
// è¯­éŸ³è¯†åˆ«é”™è¯¯å¤„ç†
const recognizer = audioProcessor.getSpeechRecognizer();
if (recognizer) {
    recognizer.onError = (error) => {
        switch (error) {
            case 'no-speech':
                console.log('æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³');
                break;
            case 'audio-capture':
                console.log('éº¦å…‹é£è®¿é—®è¢«æ‹’ç»');
                break;
            case 'not-allowed':
                console.log('è¯­éŸ³è¯†åˆ«æƒé™è¢«æ‹’ç»');
                break;
            default:
                console.log('è¯†åˆ«é”™è¯¯:', error);
        }
    };
}

// è¯­éŸ³åˆæˆé”™è¯¯å¤„ç†
try {
    await audioProcessor.speakText('æµ‹è¯•æ–‡æœ¬');
} catch (error) {
    if (error.message.includes('not supported')) {
        console.log('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åˆæˆ');
    } else {
        console.log('åˆæˆé”™è¯¯:', error.message);
    }
}
```

## å®Œæ•´ç¤ºä¾‹

æŸ¥çœ‹ `speech-usage-example.tsx` æ–‡ä»¶è·å–å®Œæ•´çš„ React ç»„ä»¶ç¤ºä¾‹ã€‚